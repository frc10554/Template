package frc.robot.subsystems.vision

import edu.wpi.first.math.Matrix
import edu.wpi.first.math.VecBuilder
import edu.wpi.first.math.geometry.Pose2d
import edu.wpi.first.math.geometry.Pose3d
import edu.wpi.first.math.geometry.Rotation2d
import edu.wpi.first.math.numbers.N1
import edu.wpi.first.math.numbers.N3
import edu.wpi.first.wpilibj.Alert
import edu.wpi.first.wpilibj.Alert.AlertType
import edu.wpi.first.wpilibj2.command.SubsystemBase
import frc.robot.VisionConstants
import org.littletonrobotics.junction.Logger
import java.util.*
import kotlin.math.abs
import kotlin.math.pow

class Vision(
    private val consumer: VisionConsumer,
    private vararg val io: VisionIO
) : SubsystemBase() {

    private val inputs: Array<VisionIOInputsAutoLogged> = Array(io.size) { VisionIOInputsAutoLogged() }
    private val disconnectedAlerts: Array<Alert> = Array(io.size) { i ->
        Alert("Vision camera $i is disconnected.", AlertType.kWarning)
    }
    private val summary = VisionSummaryAutoLogged()

    /**
     * Returns the X angle to the best target, which can be used for simple servoing with vision.
     *
     * @param cameraIndex The index of the camera to use.
     */
    fun getTargetX(cameraIndex: Int): Rotation2d {
        return inputs[cameraIndex].latestTargetObservation.tx
    }

    override fun periodic() {
        for (i in io.indices) {
            io[i].updateInputs(inputs[i])
            Logger.processInputs("Vision/Camera$i", inputs[i])
        }

        // Initialize logging values
        val allTagPoses = LinkedList<Pose3d>()
        val allRobotPoses = LinkedList<Pose3d>()
        val allRobotPosesAccepted = LinkedList<Pose3d>()
        val allRobotPosesRejected = LinkedList<Pose3d>()

        // Loop over cameras
        for (cameraIndex in io.indices) {
            // Update disconnected alert
            disconnectedAlerts[cameraIndex].set(!inputs[cameraIndex].connected)

            // Initialize logging values
            val tagPoses = LinkedList<Pose3d>()
            val robotPoses = LinkedList<Pose3d>()
            val robotPosesAccepted = LinkedList<Pose3d>()
            val robotPosesRejected = LinkedList<Pose3d>()

            // Add tag poses
            for (tagId in inputs[cameraIndex].tagIds) {
                val tagPose = VisionConstants.aprilTagLayout.getTagPose(tagId)
                if (tagPose.isPresent) {
                    tagPoses.add(tagPose.get())
                }
            }

            // Loop over pose observations
            for (observation in inputs[cameraIndex].poseObservations) {
                // Check whether to reject pose
                val rejectPose = (observation.tagCount == 0 // Must have at least one tag
                        || (observation.tagCount == 1 && observation.ambiguity > VisionConstants.maxAmbiguity) // Cannot be high ambiguity
                        || abs(observation.pose.z) > VisionConstants.maxZError // Must have realistic Z coordinate
                        // Must be within the field boundaries
                        || observation.pose.x < 0.0
                        || observation.pose.x > VisionConstants.aprilTagLayout.fieldLength
                        || observation.pose.y < 0.0
                        || observation.pose.y > VisionConstants.aprilTagLayout.fieldWidth)

                // Add pose to log
                robotPoses.add(observation.pose)
                if (rejectPose) {
                    robotPosesRejected.add(observation.pose)
                } else {
                    robotPosesAccepted.add(observation.pose)
                }

                // Skip if rejected
                if (rejectPose) {
                    continue
                }

                // Calculate standard deviations
                val stdDevFactor = observation.averageTagDistance.pow(2.0) / observation.tagCount
                var linearStdDev = VisionConstants.linearStdDevBaseline * stdDevFactor
                var angularStdDev = VisionConstants.angularStdDevBaseline * stdDevFactor

                if (observation.type == PoseObservationType.MEGATAG_2) {
                    linearStdDev *= VisionConstants.linearStdDevMegatag2Factor
                    angularStdDev *= VisionConstants.angularStdDevMegatag2Factor
                }

                if (cameraIndex < VisionConstants.cameraStdDevFactors.size) {
                    linearStdDev *= VisionConstants.cameraStdDevFactors[cameraIndex]
                    angularStdDev *= VisionConstants.cameraStdDevFactors[cameraIndex]
                }

                // Send vision observation
                consumer.accept(
                    observation.pose.toPose2d(),
                    observation.timestamp,
                    VecBuilder.fill(linearStdDev, linearStdDev, angularStdDev)
                )
            }

            // Log camera data
            Logger.recordOutput(
                "Vision/Camera$cameraIndex/TagPoses",
                *tagPoses.toTypedArray()
            )
            Logger.recordOutput(
                "Vision/Camera$cameraIndex/RobotPoses",
                *robotPoses.toTypedArray()
            )
            Logger.recordOutput(
                "Vision/Camera$cameraIndex/RobotPosesAccepted",
                *robotPosesAccepted.toTypedArray()
            )
            Logger.recordOutput(
                "Vision/Camera$cameraIndex/RobotPosesRejected",
                *robotPosesRejected.toTypedArray()
            )

            allTagPoses.addAll(tagPoses)
            allRobotPoses.addAll(robotPoses)
            allRobotPosesAccepted.addAll(robotPosesAccepted)
            allRobotPosesRejected.addAll(robotPosesRejected)
        }

        // Log summary data
        summary.tagPoses = allTagPoses.toTypedArray()
        summary.robotPoses = allRobotPoses.toTypedArray()
        summary.robotPosesAccepted = allRobotPosesAccepted.toTypedArray()
        summary.robotPosesRejected = allRobotPosesRejected.toTypedArray()
        Logger.processInputs("Vision/Summary", summary)
    }

    fun interface VisionConsumer {
        fun accept(
            visionRobotPoseMeters: Pose2d,
            timestampSeconds: Double,
            visionMeasurementStdDevs: Matrix<N3, N1>
        )
    }
}
